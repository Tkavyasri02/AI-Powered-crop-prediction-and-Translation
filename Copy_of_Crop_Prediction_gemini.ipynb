{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGVQHlEQPDEh",
        "outputId": "12280a92-4cbe-4b01-f62e-24446d07783c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 2.569s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvTfKPDhajBm",
        "outputId": "93d14ffe-81fa-45b2-891f-7097ef56412e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.0 smmap-5.0.1 streamlit-1.33.0 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILBBbnruPV3w",
        "outputId": "3f91bb41-11d5-4ecc-9794-9d9811c2f04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==3.1.0a0)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hstspreload-2024.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16353 sha256=9729077f62dddaca32b6b9c03adb578a482dbc83337d5a3731578efad7607fe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/5d/3c/8477d0af4ca2b8b1308812c09f1930863caeebc762fe265a95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.4.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans==3.1.0a0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"üîë\" in the left panel. Give it the name `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY']=\"AIzaSyDicS74V4tbFJLAj59Sr6MaiE5tTjkJo9Q\"\n",
        "# GOOGLE_API_KEY=userdata.get('AIzaSyDicS74V4tbFJLAj59Sr6MaiE5tTjkJo9Q')\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDicS74V4tbFJLAj59Sr6MaiE5tTjkJo9Q\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "\n",
        "In the simplest case, you can pass a prompt string to the <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a> method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "he-OfzBbhACQ",
        "outputId": "bb84c6d4-e6d7-42ab-c119-b7ef3fdc3a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 248 ms, sys: 33.5 ms, total: 281 ms\n",
            "Wall time: 16.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"What is the meaning of life?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbrR-n_qlpFd"
      },
      "source": [
        "In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "G-zBkueElVEO",
        "outputId": "9c711fdf-270b-4fc3-e43b-f8f47453f7df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The meaning of life is a philosophical question that has been pondered by humans for thousands of years. There is no one definitive answer, as the meaning of life is subjective and personal. However, some common themes that emerge when discussing the meaning of life include:\n> \n> * **Purpose:** What is your unique purpose or calling in life? What are you meant to do with your time on Earth?\n> * **Values:** What are your core values and beliefs? What is important to you and why?\n> * **Relationships:** Who are the people who make your life meaningful? How can you nurture and strengthen these relationships?\n> * **Contribution:** How can you make a positive contribution to the world? What legacy do you want to leave behind?\n> * **Happiness:** What makes you happy and fulfilled? How can you create more of these experiences in your life?\n> \n> Ultimately, the meaning of life is something that you must discover for yourself. There is no right or wrong answer, and your meaning may change over time. The important thing is to live a life that is true to your values and that brings you joy and fulfillment.\n> \n> Here are some additional thoughts on the meaning of life:\n> \n> * The meaning of life is not something that you can find once and for all. It is an ongoing journey of discovery and growth.\n> * The meaning of life is not something that is given to you by someone else. It is something that you create for yourself.\n> * The meaning of life is not something that you can achieve overnight. It takes time, effort, and reflection.\n> * The meaning of life is not something that you can control. There will be times when you feel lost or uncertain. But even in these times, it is important to keep searching for meaning.\n> \n> The meaning of life is a complex and personal question. There is no one right answer, but there are many different ways to find meaning in your life. The important thing is to live a life that is true to your values and that brings you joy and fulfillment."
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La3HWof8Qf0Z",
        "outputId": "7df5dfbb-7c48-44b7-c486-fdf023e89b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "Collecting audio_recorder_streamlit\n",
            "  Downloading audio_recorder_streamlit-0.0.8-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from audio_recorder_streamlit) (1.33.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (0.9.0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->audio_recorder_streamlit) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->audio_recorder_streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->audio_recorder_streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->audio_recorder_streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->audio_recorder_streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->audio_recorder_streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->audio_recorder_streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->audio_recorder_streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->audio_recorder_streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->audio_recorder_streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->audio_recorder_streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->audio_recorder_streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->audio_recorder_streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->audio_recorder_streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit>=0.63->audio_recorder_streamlit) (1.16.0)\n",
            "Installing collected packages: audio_recorder_streamlit\n",
            "Successfully installed audio_recorder_streamlit-0.0.8\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame\n",
        "!pip install audio_recorder_streamlit\n",
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zQBabuzQfyA",
        "outputId": "dae9aebd-7989-43e8-e92c-510559bcd80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Shape of the Dataset : (2200, 8)\n",
            "(2200, 7)\n",
            "Shape of x: (2200, 7)\n",
            "Shape of y: (2200,)\n",
            "The Shape of x train: (1760, 7)\n",
            "The Shape of x test: (440, 7)\n",
            "The Shape of y train: (1760,)\n",
            "The Shape of y test: (440,)\n"
          ]
        }
      ],
      "source": [
        "from audio_recorder_streamlit import audio_recorder\n",
        "import speech_recognition as sr\n",
        "import pygame\n",
        "# for manipulations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tempfile import NamedTemporaryFile\n",
        "# for data visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# for interactivity\n",
        "import ipywidgets\n",
        "from ipywidgets import interact\n",
        "data = pd.read_excel('data.xlsx')\n",
        "\n",
        "# lets check teh shape of the dataset\n",
        "print(\"Shape of the Dataset :\", data.shape)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Lets select the Spending score, and Annual Income Columns from the Data\n",
        "x = data.loc[:, ['N','P','K','temperature','ph','humidity','rainfall']].values\n",
        "\n",
        "# let's check the shape of x\n",
        "print(x.shape)\n",
        "\n",
        "# lets convert this data into a dataframe\n",
        "x_data  = pd.DataFrame(x)\n",
        "x_data.head()\n",
        "# lets split the Dataset for Predictive Modelling\n",
        "\n",
        "y = data['label']\n",
        "x = data.drop(['label'], axis = 1)\n",
        "\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "# lets create Training and Testing Sets for Validation of Results\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(\"The Shape of x train:\", x_train.shape)\n",
        "print(\"The Shape of x test:\", x_test.shape)\n",
        "print(\"The Shape of y train:\", y_train.shape)\n",
        "print(\"The Shape of y test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "YBlRs_8jQfva",
        "outputId": "6da047fa-2632-420e-a9e2-ec457f579056"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=22,\n",
              "              num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=22,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=22,\n",
              "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# lets create a Predictive Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(x_train, y_train)\n",
        "\n",
        " # Train XGBoost model\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(data['label'].unique()))\n",
        "xgb_model.fit(x_train, y_train_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJJBAMIQfs5",
        "outputId": "546b242b-1f97-4e0b-fb84-fb0db5132850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Suggested Crop for Given Climatic Condition is : orange\n"
          ]
        }
      ],
      "source": [
        "prediction = xgb_model.predict((np.array([[20,\n",
        "                                       30,\n",
        "                                       10,\n",
        "                                       15,\n",
        "                                       90,\n",
        "                                       7.5,\n",
        "                                       100]])))\n",
        "xgboost_prediction = label_encoder.inverse_transform(prediction)[0]\n",
        "print(\"The Suggested Crop for Given Climatic Condition is :\",xgboost_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_5h8GgUBQfjB",
        "outputId": "696e76de-25f8-490b-90e5-3ea64243de08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Suggested Crop: Oranges**\n> \n> **Necessary Measures and Suggestions:**\n> \n> * **Choose the right variety:** Select orange varieties suitable for the local climate and soil conditions.\n> * **Plant in well-drained soil:** Oranges prefer well-drained, sandy or loamy soil with a pH of 5.5 to 6.5.\n> * **Provide adequate sunlight:** Plant trees in areas receiving at least 6-8 hours of sunlight per day.\n> * **Water regularly:** Water trees deeply and regularly, especially during hot and dry weather.\n> * **Fertilize appropriately:** Apply a balanced fertilizer every 3-4 months during the growing season.\n> * **Prune for health and productivity:** Prune trees to remove dead or diseased branches, improve airflow, and encourage fruit production.\n> * **Control pests and diseases:** Monitor trees for pests and diseases and take appropriate control measures as needed.\n> * **Harvest at optimal ripeness:** Oranges should be harvested when they reach their desired color and sweetness.\n> * **Consider grafting:** Grafting can introduce desirable traits, such as disease resistance or early fruiting, to existing trees.\n> * **Use mulches:** Organic mulches help retain moisture, suppress weeds, and improve soil health.\n> * **Install windbreaks:** Windbreaks protect trees from strong winds that can damage branches and fruit."
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "prompt = f\"The predicted crop is {xgboost_prediction}. Please provide a brief response on the suggested crop and any necessary measures and suggestions for the farmer.\"\n",
        "response = model.generate_content(prompt)\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "80tcOf6GRW6w"
      },
      "outputs": [],
      "source": [
        "import googletrans\n",
        "from googletrans import Translator\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "WCV-pk-NRyAo",
        "outputId": "c3d42f9c-2502-42c9-9a61-c3880fdbbacf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **‡∞∏‡±Ç‡∞ö‡∞ø‡∞§ ‡∞™‡∞Ç‡∞ü: ‡∞®‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ú**\n> \n> **‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Æ‡±à‡∞® ‡∞ö‡∞∞‡±ç‡∞Ø‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡±Ç‡∞ö‡∞®‡∞≤‡±Å:**\n> \n> * **‡∞∏‡∞∞‡±à‡∞® ‡∞∞‡∞ï‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:** ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï ‡∞µ‡∞æ‡∞§‡∞æ‡∞µ‡∞∞‡∞£‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞®‡±á‡∞≤ ‡∞™‡∞∞‡∞ø‡∞∏‡±ç‡∞•‡∞ø‡∞§‡±Å‡∞≤‡∞ï‡±Å ‡∞§‡∞ó‡∞ø‡∞® ‡∞®‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ú ‡∞∞‡∞ï‡∞æ‡∞≤‡∞®‡±Å ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø.\n> * **‡∞¨‡∞æ‡∞ó‡∞æ ‡∞é‡∞Ç‡∞°‡∞ø‡∞™‡±ã‡∞Ø‡∞ø‡∞® ‡∞®‡±á‡∞≤‡∞≤‡±ã ‡∞®‡∞æ‡∞ü‡∞Ç‡∞°‡∞ø:** ‡∞®‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ú‡∞≤‡±Å 5.5 ‡∞®‡±Å‡∞Ç‡∞°‡∞ø 6.5 pH ‡∞µ‡∞∞‡∞ï‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ ‡∞é‡∞Ç‡∞°‡∞ø‡∞™‡±ã‡∞Ø‡∞ø‡∞®, ‡∞á‡∞∏‡±Å‡∞ï ‡∞≤‡±á‡∞¶‡∞æ ‡∞≤‡±ã‡∞Æ‡±Ä ‡∞®‡±á‡∞≤‡∞®‡±Å ‡∞á‡∞∑‡±ç‡∞ü‡∞™‡∞°‡∞§‡∞æ‡∞Ø‡∞ø.\n> * **‡∞§‡∞ó‡∞ø‡∞®‡∞Ç‡∞§ ‡∞∏‡±Ç‡∞∞‡±ç‡∞Ø‡∞∞‡∞∂‡±ç‡∞Æ‡∞ø‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:** ‡∞∞‡±ã‡∞ú‡±Å‡∞ï‡±Å ‡∞ï‡∞®‡±Ä‡∞∏‡∞Ç 6-8 ‡∞ó‡∞Ç‡∞ü‡∞≤ ‡∞∏‡±Ç‡∞∞‡±ç‡∞Ø‡∞∞‡∞∂‡±ç‡∞Æ‡∞ø‡∞®‡∞ø ‡∞™‡±ä‡∞Ç‡∞¶‡±á ‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡∞≤‡±ã ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞®‡∞æ‡∞ü‡∞Ç‡∞°‡∞ø.\n> * ** ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ç ‡∞§‡∞™‡±ç‡∞™‡∞ï‡±Å‡∞Ç‡∞°‡∞æ ‡∞®‡±Ä‡∞∞‡±Å:** ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞ï‡±Å ‡∞≤‡±ã‡∞§‡±Å‡∞ó‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ç ‡∞§‡∞™‡±ç‡∞™‡∞ï‡±Å‡∞Ç‡∞°‡∞æ ‡∞®‡±Ä‡∞∞‡±Å ‡∞™‡±Ü‡∞ü‡±ç‡∞ü‡∞Ç‡∞°‡∞ø, ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Ç‡∞ó‡∞æ ‡∞µ‡±á‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ä‡∞°‡∞ø ‡∞µ‡∞æ‡∞§‡∞æ‡∞µ‡∞∞‡∞£‡∞Ç‡∞≤‡±ã.\n> * **‡∞∏‡∞∞‡∞ø‡∞Ø‡±à‡∞® ‡∞é‡∞∞‡±Å‡∞µ‡±Å‡∞≤‡±Å ‡∞µ‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:** ‡∞™‡±Ü‡∞∞‡±Å‡∞ó‡±Å‡∞§‡±Å‡∞®‡±ç‡∞® ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã ‡∞™‡±ç‡∞∞‡∞§‡∞ø 3-4 ‡∞®‡±Ü‡∞≤‡∞≤‡∞ï‡±Å ‡∞∏‡∞Æ‡∞§‡±Å‡∞≤‡±ç‡∞Ø ‡∞é‡∞∞‡±Å‡∞µ‡±Å‡∞≤‡±Å ‡∞µ‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.\n> * **‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞â‡∞§‡±ç‡∞™‡∞æ‡∞¶‡∞ï‡∞§ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞ï‡∞§‡±ç‡∞§‡∞ø‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:** ‡∞ö‡∞®‡∞ø‡∞™‡±ã‡∞Ø‡∞ø‡∞® ‡∞≤‡±á‡∞¶‡∞æ ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø‡∞ó‡±ç‡∞∞‡∞∏‡±ç‡∞§‡±Å‡∞≤‡±à‡∞® ‡∞ï‡±ä‡∞Æ‡±ç‡∞Æ‡∞≤‡∞®‡±Å ‡∞§‡±ä‡∞≤‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞ó‡∞æ‡∞≤‡∞ø ‡∞™‡±ç‡∞∞‡∞µ‡∞æ‡∞π‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±Ü‡∞∞‡±Å‡∞ó‡±Å‡∞™‡∞∞‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞Ç‡∞°‡±ç‡∞≤ ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡±ã‡∞§‡±ç‡∞∏‡∞π‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞ï‡∞§‡±ç‡∞§‡∞ø‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.\n> * ** ‡∞§‡±Ü‡∞ó‡±Å‡∞≥‡±ç‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡±Å‡∞≤‡∞®‡±Å ‡∞®‡∞ø‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:** ‡∞§‡±Ü‡∞ó‡±Å‡∞≥‡±ç‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Æ‡±à‡∞® ‡∞µ‡∞ø‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞§‡∞ó‡∞ø‡∞® ‡∞®‡∞ø‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞‡∞£ ‡∞ö‡∞∞‡±ç‡∞Ø‡∞≤‡±Å ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø.\n> * ** ‡∞∏‡∞∞‡±à‡∞® ‡∞™‡∞ï‡±ç‡∞µ‡∞§ ‡∞µ‡∞¶‡±ç‡∞¶ ‡∞™‡∞Ç‡∞ü:** ‡∞®‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ú‡∞≤‡±Å ‡∞µ‡∞æ‡∞ü‡∞ø ‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞® ‡∞∞‡∞Ç‡∞ó‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞§‡±Ä‡∞™‡∞ø‡∞®‡∞ø ‡∞ö‡±á‡∞∞‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞™‡∞Ç‡∞°‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø.\n> * **‡∞Ö‡∞Ç‡∞ü‡±Å‡∞ï‡∞ü‡±ç‡∞ü‡±Å‡∞ü‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:** ‡∞Ö‡∞Ç‡∞ü‡±Å‡∞ï‡∞ü‡±ç‡∞ü‡±Å‡∞ü ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±á ‡∞â‡∞®‡±ç‡∞® ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞ï‡±Å ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞®‡∞ø‡∞∞‡±ã‡∞ß‡∞ï‡∞§ ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ‡∞®‡±á ‡∞´‡∞≤‡∞æ‡∞≤‡±Å ‡∞ï‡∞æ‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø ‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞ö‡∞Ø‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.\n> * **‡∞Æ‡∞≤‡±ç‡∞ö‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:** ‡∞Ü‡∞∞‡±ç‡∞ó‡∞æ‡∞®‡∞ø‡∞ï‡±ç ‡∞Æ‡∞≤‡±ç‡∞ö‡±ç‚Äå‡∞≤‡±Å ‡∞§‡±á‡∞Æ‡∞®‡±Å ‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç, ‡∞ï‡∞≤‡±Å‡∞™‡±Å ‡∞Æ‡±ä‡∞ï‡±ç‡∞ï‡∞≤‡∞®‡±Å ‡∞Ö‡∞£‡∞ö‡∞ø‡∞µ‡±á‡∞Ø‡∞°‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞®‡±á‡∞≤ ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±Ü‡∞∞‡±Å‡∞ó‡±Å‡∞™‡∞∞‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞π‡∞æ‡∞Ø‡∞™‡∞°‡∞§‡∞æ‡∞Ø‡∞ø.\n> * **‡∞µ‡∞ø‡∞Ç‡∞°‡±ç‚Äå‡∞¨‡±ç‡∞∞‡±á‡∞ï‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞á‡∞®‡±ç‚Äå‡∞∏‡±ç‡∞ü‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:** ‡∞µ‡∞ø‡∞Ç‡∞°‡±ç‚Äå‡∞¨‡±ç‡∞∞‡±á‡∞ï‡±ç‚Äå‡∞≤‡±Å ‡∞ï‡±ä‡∞Æ‡±ç‡∞Æ‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞Ç‡∞°‡±ç‡∞≤‡∞®‡±Å ‡∞¶‡±Ü‡∞¨‡±ç‡∞¨‡∞§‡±Ä‡∞∏‡±á ‡∞¨‡∞≤‡∞Æ‡±à‡∞® ‡∞ó‡∞æ‡∞≤‡±Å‡∞≤ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞ö‡±Ü‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞∞‡∞ï‡±ç‡∞∑‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞ø."
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "translator = Translator()\n",
        "translated = translator.translate(response.text, src='en', dest='te')\n",
        "to_markdown(translated.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "SxVHa4H1W3jb",
        "outputId": "ec1d9b83-4a5b-416e-b796-0b3bd2cd542f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given details about crop conditions:\n",
            "                    climatic conditions : cool to moderate temperatures (15¬∞C to 25¬∞C),\n",
            "well-distributed rainfall (500-800 mm annually), loose, well-drained fertile soil,\n",
            "adequate sunlight exposure (6-8 hours/day), avoidance of extreme heat or frost,\n",
            "moderate relative humidity (60%-80%), and no waterlogging.\n",
            "                  Extract values of NPK levels, temperature, pH, humidity and rainfall from the above text.If insufficient data is given,\n",
            "                  Generate random postive integer values in the below foramt:\n",
            "                  Don't return anything except the response as a string:([N, P, K, temperature, ph, humidity, rainfall])\n",
            "                  example: '[100, 40, 40, 25, 7, 50, 200]'\n",
            "[0, 0, 0, 20, 0, 70, 650]\n",
            "['0', '0', '0', '20', '0', '70', '650']\n"
          ]
        }
      ],
      "source": [
        "num_prompt=\"\"\"climatic conditions : cool to moderate temperatures (15¬∞C to 25¬∞C),\n",
        "well-distributed rainfall (500-800 mm annually), loose, well-drained fertile soil,\n",
        "adequate sunlight exposure (6-8 hours/day), avoidance of extreme heat or frost,\n",
        "moderate relative humidity (60%-80%), and no waterlogging.\"\"\"\n",
        "summary_prompt = f\"\"\"Given details about crop conditions:\n",
        "                    {num_prompt}\n",
        "                  Extract values of NPK levels, temperature, pH, humidity and rainfall from the above text.If insufficient data is given,\n",
        "                  Generate random postive integer values in the below foramt:\n",
        "                  Don't return anything except the response as a string:([N, P, K, temperature, ph, humidity, rainfall])\n",
        "                  example: '[100, 40, 40, 25, 7, 50, 200]'\"\"\"\n",
        "print(summary_prompt)\n",
        "input_data = model.generate_content(summary_prompt)\n",
        "inp = input_data.text\n",
        "print(inp)\n",
        "data_list = inp.strip('[]').split(', ')\n",
        "print(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHj1RsaRfKds",
        "outputId": "40e68daa-788b-4667-e04e-fa09d53729da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPXGhvPbTfxI",
        "outputId": "e4f6633f-416d-458a-be56-348e1ac03bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing xgb.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile xgb.py\n",
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import streamlit as st\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import pygame\n",
        "import speech_recognition as sr\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tempfile import NamedTemporaryFile\n",
        "from audio_recorder_streamlit import audio_recorder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Function to play audio\n",
        "def play_audio(file_path):\n",
        "    pygame.mixer.init()\n",
        "    pygame.mixer.music.load(file_path)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "def main():\n",
        "    os.environ['GOOGLE_API_KEY']=\"AIzaSyDicS74V4tbFJLAj59Sr6MaiE5tTjkJo9Q\"\n",
        "    genai.configure(api_key=\"AIzaSyDicS74V4tbFJLAj59Sr6MaiE5tTjkJo9Q\")\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    data = pd.read_excel('data.xlsx')\n",
        "    # Select features and target variable\n",
        "    features = ['N', 'P', 'K', 'temperature', 'ph', 'humidity', 'rainfall']\n",
        "    target = 'label'\n",
        "    X = data[features]\n",
        "    y = data[target]\n",
        "    st.title(\"Crop Prediction and Translation App\")\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    logistic_model = LogisticRegression()\n",
        "    logistic_model.fit(X_train, y_train)\n",
        "\n",
        "    # Train XGBoost model\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(data['label'].unique()))\n",
        "    xgb_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "\n",
        "\n",
        "    # Translator method for translation\n",
        "    translator = Translator()\n",
        "    # Streamlit UI components\n",
        "    input_mode = st.radio(\"Select Input Mode:\", (\"Text\", \"Audio\",\"Pick\"))\n",
        "\n",
        "    if input_mode == \"Text\":\n",
        "        get_sentence = st.text_area(\"Enter the Query:\")\n",
        "\n",
        "        # Dropdown for destination language selection\n",
        "        dest_lang_options = {'en': 'English', 'hi': 'Hindi', 'gu': 'Gujarati', 'mr': 'Marathi', 'bn': 'Bengali', 'pa': 'Punjabi', 'ta': 'Tamil', 'te': 'Telugu', 'kn': 'Kannada', 'ml': 'Malayalam', 'ur': 'Urdu'}\n",
        "        dest_lang = st.selectbox(\"Select destination language:\", list(dest_lang_options.keys()), format_func=lambda x: dest_lang_options[x])\n",
        "\n",
        "\n",
        "        if st.button(\"Translate, Predict, and Generate Response\"):\n",
        "            try:\n",
        "                # Translator method for translation\n",
        "                translator = Translator()\n",
        "                # Using translate() method to convert text\n",
        "                text_to_translate = translator.translate(get_sentence, dest='en')\n",
        "                summary_prompt = f\"\"\"Given details about crop conditions:\n",
        "                    {text_to_translate}\n",
        "                  Extract values of NPK levels, temperature, pH, humidity and rainfall from the above text.If insufficient data is given,\n",
        "                  Generate random postive integer values in the below foramt:\n",
        "                  Don't return anything except the response as a string:([N, P, K, temperature, ph, humidity, rainfall])\n",
        "                  example: '[100, 40, 40, 25, 7, 50, 200]'\"\"\"\n",
        "                input_data = model.generate_content(summary_prompt)\n",
        "                inp = input_data.text\n",
        "                data_list = inp.strip('[]').split(', ')\n",
        "\n",
        "                # Convert the string elements to integers\n",
        "                data_int = [int(x.strip()) for x in data_list if x.strip().isdigit()]\n",
        "                # Convert the list to a numpy array\n",
        "                input_data = np.array([data_int])\n",
        "                prediction = xgb_model.predict(input_data)\n",
        "                xgboost_prediction = label_encoder.inverse_transform(prediction)[0]\n",
        "                st.write('Predicted Crop:', xgboost_prediction)\n",
        "\n",
        "\n",
        "                prompt = f\"The predicted crop is {xgboost_prediction}. Please provide a brief response on the suggested crop and any necessary measures and suggestions for the farmer.\"\n",
        "                response = model.generate_content(prompt)\n",
        "                translated = translator.translate(response.text, src='en', dest=dest_lang)\n",
        "                st.markdown(translated.text)\n",
        "\n",
        "                # Using gTTS to convert the translated text to speech\n",
        "                # tts = gTTS(text=response.text, lang=dest_lang, slow=False)\n",
        "                # audio_file_path = NamedTemporaryFile(delete=False, suffix=\".mp3\").name\n",
        "                # tts.save(audio_file_path)\n",
        "                # # Playing the generated audio\n",
        "                # play_audio(audio_file_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(\"An error occurred: {}\".format(e))\n",
        "\n",
        "    elif input_mode == \"Audio\":\n",
        "        audio_bytes = audio_recorder(pause_threshold=2.0, sample_rate=41_000)\n",
        "        if audio_bytes:\n",
        "            st.audio(audio_bytes, format=\"audio/wav\")\n",
        "\n",
        "            # Save the audio file as output_audio.wav\n",
        "            with open(\"output_audio.wav\", \"wb\") as audio_file:\n",
        "                audio_file.write(audio_bytes)\n",
        "\n",
        "            # Use the saved audio file for translation and text-to-speech\n",
        "            try:\n",
        "                dest_lang_options = {'en': 'English', 'hi': 'Hindi', 'gu': 'Gujarati', 'mr': 'Marathi', 'bn': 'Bengali', 'pa': 'Punjabi', 'ta': 'Tamil', 'te': 'Telugu', 'kn': 'Kannada', 'ml': 'Malayalam', 'ur': 'Urdu'}\n",
        "                dest_lang = st.selectbox(\"Select destination language:\", list(dest_lang_options.keys()), format_func=lambda x: dest_lang_options[x])\n",
        "\n",
        "\n",
        "\n",
        "                # Recognize the speech in the saved audio file\n",
        "                recognizer = sr.Recognizer()\n",
        "                with sr.AudioFile(\"output_audio.wav\") as source:\n",
        "                    audio_data = recognizer.record(source)\n",
        "\n",
        "                # Translate the recognized text\n",
        "                text_to_translate = translator.translate(recognizer.recognize_google(audio_data), dest='en')\n",
        "                summary_prompt = f\"\"\"Given details about crop conditions:\n",
        "                    {text_to_translate}\n",
        "                  Extract values of NPK levels, temperature, pH, humidity and rainfall from the above text.If insufficient data is given,\n",
        "                  Generate random postive integer values in the below foramt:\n",
        "                  Don't return anything except the response as a string:([N, P, K, temperature, ph, humidity, rainfall])\n",
        "                  example: '[100, 40, 40, 25, 7, 50, 200]'\"\"\"\n",
        "                input_data = model.generate_content(summary_prompt)\n",
        "                inp = input_data.text\n",
        "                data_list = inp.strip('[]').split(', ')\n",
        "                # Convert the string elements to integers\n",
        "                data_int = [int(x.strip()) for x in data_list if x.strip().isdigit()]\n",
        "                # Convert the list to a numpy array\n",
        "                input_data = np.array([data_int])\n",
        "                prediction = xgb_model.predict(input_data)\n",
        "                xgboost_prediction = label_encoder.inverse_transform(prediction)[0]\n",
        "                st.write('Predicted Crop:', xgboost_prediction)\n",
        "\n",
        "\n",
        "                prompt = f\"The predicted crop is {xgboost_prediction}. Please provide a brief response on the suggested crop and any necessary measures and suggestions for the farmer.\"\n",
        "                response = model.generate_content(prompt)\n",
        "                translated = translator.translate(response.text, src='en', dest=dest_lang)\n",
        "                st.markdown(translated.text)\n",
        "\n",
        "\n",
        "                # Using gTTS to convert the translated text to speech\n",
        "                # tts = gTTS(text=response.text, lang=dest_lang, slow=False)\n",
        "                # audio_file_path = NamedTemporaryFile(delete=False, suffix=\".mp3\").name\n",
        "                # tts.save(audio_file_path)\n",
        "                # # Playing the generated audio\n",
        "                # play_audio(audio_file_path)\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(\"An error occurred: {}\".format(e))\n",
        "    else:\n",
        "\n",
        "        # Input fields for user input\n",
        "        N = st.number_input('Nitrogen (N)', min_value=0.0, max_value=1000.0, value=100.0)\n",
        "        P = st.number_input('Phosphorus (P)', min_value=0.0, max_value=1000.0, value=40.0)\n",
        "        K = st.number_input('Potassium (K)', min_value=0.0, max_value=1000.0, value=40.0)\n",
        "        temperature = st.number_input('Temperature', min_value=0.0, max_value=100.0, value=25.0)\n",
        "        ph = st.number_input('pH', min_value=0.0, max_value=14.0, value=7.0)\n",
        "        humidity = st.number_input('Humidity', min_value=0.0, max_value=100.0, value=50.0)\n",
        "        rainfall = st.number_input('Rainfall', min_value=0.0, max_value=1000.0, value=200.0)\n",
        "        input_data = np.array([[N, P, K, temperature, ph, humidity, rainfall]])\n",
        "        dest_lang_options = {'en': 'English', 'hi': 'Hindi', 'gu': 'Gujarati', 'mr': 'Marathi', 'bn': 'Bengali', 'pa': 'Punjabi', 'ta': 'Tamil', 'te': 'Telugu', 'kn': 'Kannada', 'ml': 'Malayalam', 'ur': 'Urdu'}\n",
        "        dest_lang = st.selectbox(\"Select destination language:\", list(dest_lang_options.keys()), format_func=lambda x: dest_lang_options[x])\n",
        "        if st.button(\"Predict, and Generate Response\"):\n",
        "            st.write(\"Input array: \", input_data)\n",
        "            prediction = xgb_model.predict(input_data)\n",
        "            xgboost_prediction = label_encoder.inverse_transform(prediction)[0]\n",
        "            st.write('Predicted Crop:', xgboost_prediction)\n",
        "            prompt = f\"The predicted crop is {xgboost_prediction}. Please provide a brief response on the suggested crop and any necessary measures and suggestions for the farmer.\"\n",
        "            response = model.generate_content(prompt)\n",
        "            translated = translator.translate(response.text, src='en', dest=dest_lang)\n",
        "            st.markdown(translated.text)\n",
        "            # Using gTTS to convert the translated text to speech\n",
        "            # tts = gTTS(text=response.text, lang=dest_lang, slow=False)\n",
        "            # audio_file_path = NamedTemporaryFile(delete=False, suffix=\".mp3\").name\n",
        "            # tts.save(audio_file_path)\n",
        "            # # Playing the generated audio\n",
        "            # play_audio(audio_file_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsuEf-AJdmRa",
        "outputId": "0e7ed200-09b6-4935-ca0a-6e443738dc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.245.98.234\n"
          ]
        }
      ],
      "source": [
        "#!streamlit run /content/xgb.py &>/content/logs.txt & curl ipv4.icanhazip.com\n",
        "!streamlit run /content/xgb.py --server.address=localhost &>/content/logs.txt & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zByt9x6ydz2z",
        "outputId": "9f0ac3c8-b606-4493-c4b4-51e8ac03b301"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.085s\n",
            "your url is: https://wild-onions-chew.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}